{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tensor Flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.constant(10, dtype = tf.int64)\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[4, 2],\n",
       "       [9, 2]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definign 2 D array or matrix\n",
    "c = tf.constant([[4,2], \n",
    "                [9,2]]\n",
    "                )\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2],\n",
       "       [9, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2, 2)\n",
      "Type: <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {c.shape}\")\n",
    "print(f\"Type: {c.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(np.zeros((3,3))) # Numpy way\n",
    "print(tf.zeros(shape = (2,3))) # Tensorflow way\n",
    "print(np.ones((3,3))) # Numpy way\n",
    "print(tf.ones(shape = (2,3))) # Tensorflow way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 4 5]]\n",
      "[[3 4 5]\n",
      " [1 2 3]]\n",
      "[[4 6 8]\n",
      " [4 6 8]]\n"
     ]
    }
   ],
   "source": [
    "var1 = tf.constant([\n",
    "                    [1,2,3],\n",
    "                    [ 3,4,5]\n",
    "                    ])\n",
    "print(var1.numpy())   \n",
    "var2 = tf.constant([\n",
    "                    [3,4,5],\n",
    "                    [ 1,2,3]\n",
    "                    ])\n",
    "print(var2.numpy())    \n",
    "\n",
    "result = tf.add(var1, var2)\n",
    "\n",
    "print(result.numpy())             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.1782393  -0.32456023]\n",
      " [ 2.2323263   0.79020345]], shape=(2, 2), dtype=float32)\n",
      "42\n",
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 9 10 11]]]\n"
     ]
    }
   ],
   "source": [
    "print(tf.random.normal(shape = (2,2), mean=0)) # Craeting 2X2 marix with mean equal to 0\n",
    "\n",
    "var0 = tf.Variable(42) # rank zero tensor output\n",
    "print(var0.numpy()) \n",
    "\n",
    "var1 = tf.Variable([[\n",
    "                    [0,1,2],\n",
    "                    [3,4,5],\n",
    "                    [9,10,11]\n",
    "                    ]]) # rank 3 tensor output\n",
    "print(var1.numpy()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float64'>\n",
      "45.0\n"
     ]
    }
   ],
   "source": [
    "var4 = tf.Variable(45, dtype = tf.float64) # Defining float point variable\n",
    "print(var4.dtype)\n",
    "print(var4.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "var5 = tf.constant([1,2,3,4,5])\n",
    "rank = var5.ndim # Getting rank\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation on simple dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.mnist\n",
    "(train_x, train_y), (test_x, test_y) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.keras.datasets.mnist' from 'd:\\\\Personal Files\\\\NLP_Bootcamp\\\\venv\\\\lib\\\\site-packages\\\\tensorflow\\\\keras\\\\datasets\\\\mnist\\\\__init__.py'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = tf.cast(train_x/255, tf.float64), tf.cast(test_x/255, tf.float64) # Normalizing\n",
    "train_y, test_y = tf.cast(train_y/255, tf.int64), tf.cast(test_y/255, tf.int64) # Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000,), dtype=int64, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int64)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape = (28,28)), # Flatten will conver 2-D or 3-D into 1-D for the input\n",
    "tf.keras.layers.Dense(512, activation = tf.nn.relu), # Fully connected layer, 512 neuron, 512 data at a point will be passed\n",
    "tf.keras.layers.Dropout(0.2), # Regularization technique -  we can prevent overfitting. using droput we can pass random % (here is 20%) of data. Everytime we are updating 20 % of the data here\n",
    "tf.keras.layers.Dense(10, activation = tf.nn.softmax) # Output layer, Softmax for multiclassification problem\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss = \"SparseCategoricalCrossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 12s 5ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 6.3772e-07 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 1.7801e-07 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 9.6741e-08 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 4.4863e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c71387160>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size = 32, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0967e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0967239338910417e-09, 1.0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2nd way to create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.2263e-06 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 3.8089e-07 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.8484e-07 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 8.0269e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c736dd430>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = tf.keras.models.Sequential()\n",
    "model1.add(tf.keras.layers.Flatten(input_shape = (28,28))) # Flatten will conver 2-D or 3-D into 1-D for the input\n",
    "model1.add(tf.keras.layers.Dense(512, activation = tf.nn.relu)) # Fully connected layer, 512 neuron, 512 data at a point will be passed\n",
    "model1.add(tf.keras.layers.Dropout(0.2)) # Regularization technique -  we can prevent overfitting. using droput we can pass random % (here is 20%) of data. Everytime we are updating 20 % of the data here\n",
    "model1.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax)) # Output layer, Softmax for multiclassification problem\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model1.compile(optimizer, loss = \"SparseCategoricalCrossentropy\", metrics = ['accuracy'])\n",
    "model1.fit(train_x, train_y, batch_size = 32, epochs = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.9908e-09 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model1.evaluate(test_x, test_y)\n",
    "model1.save(\"./model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3rd Way to create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = tf.keras.models.Sequential()\n",
    "# x= tf.keras.layers.Flatten(input_shape = (28,28))(model2) # Flatten will conver 2-D or 3-D into 1-D for the input\n",
    "# y = tf.keras.layers.Dense(512, activation = tf.nn.relu)(x) # Fully connected layer, 512 neuron, 512 data at a point will be passed\n",
    "# z = tf.keras.layers.Dropout(0.2)(y) # Regularization technique -  we can prevent overfitting. using droput we can pass random % (here is 20%) of data. Everytime we are updating 20 % of the data here\n",
    "# a = tf.keras.layers.Dense(10, activation = tf.nn.softmax)(z) # Output layer, Softmax for multiclassification problem\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "# a.compile(optimizer, loss = \"SparseCategoricalCrossentropy\", metrics = ['accuracy'])\n",
    "# a.fit(train_x, train_y, batch_size = 32, epochs = 5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
