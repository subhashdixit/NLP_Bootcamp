{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello my name is Shivan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am from Bangalore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello my name is Shivan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont like alcohol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text  output\n",
       "0  Hello my name is Shivan        1\n",
       "1      I am from Bangalore        1\n",
       "2  Hello my name is Shivan        1\n",
       "3       i dont like alcohol       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=[{'text':'Hello my name is Shivan ','output':1},\n",
    "                        {'text':'I am from Bangalore ','output':1}, \n",
    "                        {'text':'Hello my name is Shivan ','output':1},\n",
    "                       {'text':'i dont like alcohol','output':0}])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(df['text'])\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 5,\n",
       " 'my': 8,\n",
       " 'name': 9,\n",
       " 'is': 6,\n",
       " 'shivan': 10,\n",
       " 'am': 1,\n",
       " 'from': 4,\n",
       " 'bangalore': 2,\n",
       " 'dont': 3,\n",
       " 'like': 7,\n",
       " 'alcohol': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "- It's the mapping from word to it's ID\n",
    "\n",
    "- When calling fit on a vector each word will be mapped to the value in the dictionary.\n",
    "\n",
    "- vocabulary_ is a dict where keys are terms and values are indices in the feature matrix.\n",
    "\n",
    "CountVectorizer converts a collection of text documents to a matrix of token counts. It produces a sparse Matrix of the counts of each word from the vocabulary. The Matrix shape is NxM (N is the number of documents (rows) and M is the size of the vocabulary (columns)). This numbers are simply indices of each word of the vocabulary in this matrix across columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 1 0 1 1 1]]\n",
      "[[0 1 1 0 1 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 1 1 0 1 1 1]]\n",
      "[[1 0 0 1 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray()) # Hello my name is Shivan -> We are going to check word avaliable in our vocabulary or not ( if avaliable means 1 else 0)\n",
    "print(bow[1].toarray())\n",
    "print(bow[2].toarray())\n",
    "print(bow[3].toarray())\n",
    "# 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, \n",
    "# I am from Bangalore \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 5,\n",
       " 'my': 8,\n",
       " 'name': 9,\n",
       " 'is': 6,\n",
       " 'shivan': 10,\n",
       " 'am': 1,\n",
       " 'from': 4,\n",
       " 'bangalore': 2,\n",
       " 'dont': 3,\n",
       " 'like': 7,\n",
       " 'alcohol': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 2, 0, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform([\"hello my name is bcibuubdsiu is Shivan\"]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of vocabluy solved \n",
    "# Binary True -> It will replace all frequency to one\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "bow = cv.fit_transform(df['text'])\n",
    "cv.transform([\"hello my name is bcibuubdsiu is ketan\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are setting binary = True \n",
    "# then we are saying instead of going for frequency check that word is present or not.\n",
    "\n",
    "# max_features = build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N - Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1,1 -> uni grams\n",
    "# 2,2 -> Bi-grams\n",
    "# 1,2 -> uni + bi \n",
    "# 1,3 -> uni + bi + tri \n",
    "cv = CountVectorizer(ngram_range=(1,5))\n",
    "bow = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 10,\n",
       " 'my': 19,\n",
       " 'name': 23,\n",
       " 'is': 15,\n",
       " 'shivan': 26,\n",
       " 'hello my': 11,\n",
       " 'my name': 20,\n",
       " 'name is': 24,\n",
       " 'is shivan': 16,\n",
       " 'hello my name': 12,\n",
       " 'my name is': 21,\n",
       " 'name is shivan': 25,\n",
       " 'hello my name is': 13,\n",
       " 'my name is shivan': 22,\n",
       " 'hello my name is shivan': 14,\n",
       " 'am': 1,\n",
       " 'from': 8,\n",
       " 'bangalore': 4,\n",
       " 'am from': 2,\n",
       " 'from bangalore': 9,\n",
       " 'am from bangalore': 3,\n",
       " 'dont': 5,\n",
       " 'like': 17,\n",
       " 'alcohol': 0,\n",
       " 'dont like': 6,\n",
       " 'like alcohol': 18,\n",
       " 'dont like alcohol': 7}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf - IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In tf-idf we can implement N grams\n",
    "tf = TfidfVectorizer()\n",
    "bow = tf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4472136 , 0.4472136 , 0.        , 0.4472136 , 0.4472136 ,\n",
       "        0.4472136 ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4472136 , 0.4472136 , 0.        , 0.4472136 , 0.4472136 ,\n",
       "        0.4472136 ],\n",
       "       [0.57735027, 0.        , 0.        , 0.57735027, 0.        ,\n",
       "        0.        , 0.        , 0.57735027, 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 5,\n",
       " 'my': 8,\n",
       " 'name': 9,\n",
       " 'is': 6,\n",
       " 'shivan': 10,\n",
       " 'am': 1,\n",
       " 'from': 4,\n",
       " 'bangalore': 2,\n",
       " 'dont': 3,\n",
       " 'like': 7,\n",
       " 'alcohol': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91629073, 1.91629073, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.51082562, 1.51082562, 1.91629073, 1.51082562, 1.51082562,\n",
       "       1.51082562])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 0.       , 0.       , 0.       , 0.4472136,\n",
       "        0.4472136, 0.       , 0.4472136, 0.4472136, 0.4472136]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy Learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
